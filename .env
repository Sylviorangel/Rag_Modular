OPENAI_API_KEY=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

OPENAI_API_BASE=

CHAT_MODEL=gpt-4o-mini

# CHAT_MODEL=gpt-4o

EMBEDDING_MODEL=text-embedding-3-small

CHROMA_DIR=.chroma
COLLECTION_NAME=rag_modular

DEFAULT_SYSTEM_PROMPT=Você é um assistente técnico que responde de forma objetiva e cita fontes quando houver.

PER_CHUNK_CHARS=1500
MAX_CONTEXT_CHARS=16000
MAX_CONTEXT_CHUNKS=6

# --- Splitters ---
USE_LANGCHAIN_SPLITTER=1
CHUNK_STRATEGY=recursive_char   # recursive_char | markdown | token | code:python
CHUNK_SIZE=1200
CHUNK_OVERLAP=150

# --- Orçamento de contexto (prompt) ---
PER_CHUNK_CHARS=1500
MAX_CONTEXT_CHARS=16000
MAX_CONTEXT_CHUNKS=6

# --- Budget de embeddings ---
EMBED_MAX_TOKENS_PER_REQ=240000
EMBED_BATCH_SIZE=128
EMBED_MAX_INPUT_TOKENS=7000
